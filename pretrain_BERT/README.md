### 코더 회고
- 배운 점: BERT 모델의 사전학습 프로세스를 배웠다
- 아쉬운 점: 학습을 한 번 돌릴때마다 30분 가량이 소요되어 많은 실험을 해보지 못 했다
- 어려운 점: 모델 자체의 코드에 대한 이해가 부족하다
- 느낀 점: memmap 이외의 데이터의 크기가 클 때 사용할 수 있는 기법에 대해 더 알아보고 싶다 

---
🔑 **PRT(Peer Review Template)**
리뷰어:

- [X]  **1. 주어진 문제를 해결하는 완성된 코드가 제출되었나요? (완성도)**
    - 문제에서 요구하는 최종 결과물이 첨부되었는지 확인
    - 문제를 해결하는 완성된 코드란 프로젝트 루브릭 3개 중 2개, 
    퀘스트 문제 요구조건 등을 지칭
        - 해당 조건을 만족하는 부분의 코드 및 결과물을 캡쳐하여 사진으로 첨부
    1. 한글 코퍼스를 가공하여 BERT pretrain용 데이터셋을 잘 생성하였다.
           
    2. 구현한 BERT 모델의 학습이 안정적으로 진행됨을 확인하였다.
           
    3. 1M짜리 mini BERT 모델의 제작과 학습이 정상적으로 진행되었다.

- [X]  **2. 프로젝트에서 핵심적인 부분에 대한 설명이 주석(닥스트링) 및 마크다운 형태로 잘 기록되어있나요? (설명)**
    - [X]  모델 선정 이유

    - [X]  Metrics 선정 이유

    - [X]  Loss 선정 이유

    - 하면서 궁금했던 점에 대해서 주석을 달아놓거나   


- [X]  **3. 체크리스트에 해당하는 항목들을 모두 수행하였나요? (문제 해결)**
    - [X]  데이터를 분할하여 프로젝트를 진행했나요? (train, validation, test 데이터로 구분)<br>
    - [X]  하이퍼파라미터를 변경해가며 여러 시도를 했나요? (learning rate, dropout rate, unit, batch size, epoch 등)<br>
    - [X]  각 실험을 시각화하여 비교하였나요?  
    - [X]  모든 실험 결과가 기록되었나요?

- [X]  **4. 프로젝트에 대한 회고가 상세히 기록 되어 있나요? (회고, 정리)**
    - [X]  배운 점
    - [X]  아쉬운 점
    - [X]  느낀 점
    - [X]  어려웠던 점
