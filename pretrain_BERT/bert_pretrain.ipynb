{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de3beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59345286",
   "metadata": {},
   "source": [
    "## 토크나이저 불러오기\n",
    "SentencePiece 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03170968",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b56be",
   "metadata": {},
   "source": [
    "```\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "prefix = './models/ko_8000'\n",
    "spm.SentencePieceTrainer.train(f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={VOCAB_SIZE + 7} --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff1848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "model_dir = './models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6acdb",
   "metadata": {},
   "source": [
    "## 마스킹 생성\n",
    "단어 내 일부분에 마스킹을 적용하면 예측이 너무 쉬워지므로 띄어쓰기 단위로 잘라 단어 전체가 마스킹되도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2beb2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    # random mask를 위해서 순서를 섞음 (shuffle)\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "            \n",
    "    # 순서 정렬 및 mask_idx, mask_label 생성\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec82bf",
   "metadata": {},
   "source": [
    "## NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b5a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fdeb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line 단위로 추가\n",
    "        current_length += len(doc[i])  # current_chunk의 token 수\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0    # False\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1   # True\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "            #######################################\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        \n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "            #######################################\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf4e0e",
   "metadata": {},
   "source": [
    "## 최종 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9990cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # 생성되는 단어 목록이 unknown인 경우는 제거합니다. \n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "                    if 0 < len(doc):\n",
    "                        # save\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)    \n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                # save\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12ccdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "pretrain_json_path = './data/bert_pre_train.json'\n",
    "\n",
    "# 최종 데이터셋 json 파일로 저장\n",
    "# make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e138f45",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce26b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 적은 메모리에서도 대용량 데이터 처리가 가능\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cef7f",
   "metadata": {},
   "source": [
    "> np.memmap(): 디스크에 저장해 둔 행렬을 메모리 사용 없이 이용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba55974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7584226ab6e44d0bed018b986700e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/918189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_293/2049745891.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_293/2049745891.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_293/2049745891.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340f3541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([   5,   10, 1605, 3599, 1755, 3630,   41, 3644,  830, 3624, 1135,\n",
       "           52, 3599,   13,   81,   87, 1501, 2247,   25, 3779, 3873, 3667,\n",
       "         3631, 3813, 3873, 4196, 3636, 3779, 3601,  249, 3725, 1232,   33,\n",
       "           52, 3599,    6,    6,    6, 6322, 2780,   14, 1509,  168, 3877,\n",
       "          414,  165, 1697, 4290, 3873, 3703, 3683,  593,   21, 5007,  399,\n",
       "         1927, 3607,    6,    6,    6,    6,    6,    6,  103, 4313, 4290,\n",
       "          613, 3638, 3718,   98, 3878, 3656,  256, 2543,  309,  337, 3735,\n",
       "          181, 3616, 3603,  489,  376, 3599,    4,    6,    6,  207, 3714,\n",
       "            6, 1042,  103, 3610, 3686, 3718,    6,    6,   37, 3418,  416,\n",
       "          810, 3666, 3625,  131, 3662,    7, 3629,  203,  241, 3602, 1114,\n",
       "         3724,  788,  243,    6,    6,    6,  663, 1647, 3682, 3682, 3625,\n",
       "          203, 3008, 3625, 3616,   16, 3599,    4], dtype=int32),\n",
       " memmap([   5,   55, 3674, 3689,    4,   55, 3674, 2149,  356, 4039,  635,\n",
       "          809, 3665,   46, 4331, 3845,   10, 2494, 4567,  610, 1628, 3599,\n",
       "          445, 3663, 3698,   10,  356, 4039,  635,  809, 3986, 3838, 2006,\n",
       "         3664, 4039,  265, 3596, 4345, 3867, 3773,    9,  375, 3678,   16,\n",
       "         3599,  318, 1595, 1041,  774,  757,   38,  568, 3613,  601, 3739,\n",
       "         3791, 2170, 3656,  286, 3691,  747,  356,  337, 3891, 3680, 3989,\n",
       "         3665,    6,    6,    6,    6,    6, 1079,  485, 3656, 3874,  327,\n",
       "         3810, 3739,   16, 3599,    4,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 1,\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  479, 3652, 3625,  243,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  813,   17, 3599,  307,  587,  931,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,   18, 3686,    0,    0,\n",
       "         3324,    0,    0,    0,    0,    0,  207, 3714,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,   49, 3632,  796,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,   46, 4331, 3845,   10,  610,   38,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,  485, 3656, 1698, 3761, 3656,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c59ad5",
   "metadata": {},
   "source": [
    "# BERT 모델 구현\n",
    "> **모델 선정 이유**: BERT는 MLM을 통해 문장 전체의 문맥을 이해하고, NSP를 통해 문장 간의 관계를 이해하기 때문에 자연어의 일반적인 특징을 잘 학습할 수 있음. 따라서 사전학습 모델로 사용되기 적합함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c66168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dff357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bcd162",
   "metadata": {},
   "source": [
    "## 임베딩 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defedbc8",
   "metadata": {},
   "source": [
    "### Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6740aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe12e2",
   "metadata": {},
   "source": [
    "### Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31057de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94fa7c",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6ecf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "370c1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        # (bs, n_head, Q_len, d_head)\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)\n",
    "        # transpose and liner\n",
    "        # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.transpose(attn_out, perm=[0, 2, 1, 3])\n",
    "        # (bs, Q_len, d_model)\n",
    "        attn_out = tf.reshape(attn_out, (batch_size, -1, self.d_model))\n",
    "        # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2511fa",
   "metadata": {},
   "source": [
    "## Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277bee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e644fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda7df8",
   "metadata": {},
   "source": [
    "## pretrain을 위한 최종 BERT 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e909b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "094e6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a734f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d686e1",
   "metadata": {},
   "source": [
    "> Q. 왜 nsp를 예측할 때 softmax를 사용했을까? 이진분류니까 시그모이드를 사용해도 괜찮지 않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ccef97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404b6e8",
   "metadata": {},
   "source": [
    "# 사전학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca729005",
   "metadata": {},
   "source": [
    "### 손실함수\n",
    "> **loss 선정 이유**:  학습 데이터의 label이 정수로 변환되었으므로 loss 함수는 SparseCategoricalCrossentropy를 사용. MLM task에 대해 더 잘 학습하도록 loss를 20배 증가시켜 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe5f4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32294380",
   "metadata": {},
   "source": [
    "### 평가지표\n",
    "> **metric** 선정 이유: mlm은 마스킹 된 부분의 토큰을 맞추는 task, nsp는 두 문장이 순서대로 결합됐는지 판단하는 task이므로 정확도로 평가하는 것 적합함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8533972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9dd91",
   "metadata": {},
   "source": [
    "### 학습률 스케쥴러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8265137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db2547a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce77a2",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce122308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69349411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 28694\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008932ba",
   "metadata": {},
   "source": [
    "epoch 한 번에 약 30분이 소요되어 epoch 2로 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "539742c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14347/14347 [==============================] - 1790s 124ms/step - loss: 13.2141 - nsp_loss: 0.5245 - mlm_loss: 12.6896 - nsp_acc: 0.7461 - mlm_lm_acc: 0.1856\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.18561, saving model to ./models/bert_pre_train.hdf5\n",
      "Epoch 2/2\n",
      "14347/14347 [==============================] - 1786s 125ms/step - loss: 10.4812 - nsp_loss: 0.5035 - mlm_loss: 9.9777 - nsp_acc: 0.7668 - mlm_lm_acc: 0.2722\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.18561 to 0.27224, saving model to ./models/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c0f073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
