{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9841555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9426a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fed06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6101c2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c76aab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78283</th>\n",
       "      <td>I come from a family that used one toilet for ...</td>\n",
       "      <td>Actor Anupam Kher has said that he comes from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>855 police officers awarded medals on eve of R...</td>\n",
       "      <td>As many as 855 police personnel were awarded m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>They may kill me, but I feel no fear: Woman wh...</td>\n",
       "      <td>Bindu Ammini, one of the two women who entered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>Who is the Japanese billionaire set to be 1st ...</td>\n",
       "      <td>Billionaire Yusaku Maezawa, set to be the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>I helped Sara get on board with Karan Johar's ...</td>\n",
       "      <td>Talking about his daughter Sara Ali Khan starr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97183</th>\n",
       "      <td>World's first cannabis gym opens in US</td>\n",
       "      <td>A new gym where members can consume cannabis b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51986</th>\n",
       "      <td>9 killed as under-construction bridge collapse...</td>\n",
       "      <td>At least nine construction workers were killed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22613</th>\n",
       "      <td>Brazil judge orders to close border to Venezue...</td>\n",
       "      <td>A judge in Brazil has ordered to prevent Venez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30572</th>\n",
       "      <td>Firm makes Ã¢ÂÂ¹3-lakh iPhone X 'Tesla' with ...</td>\n",
       "      <td>Russian accessory maker Caviar has created an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89924</th>\n",
       "      <td>Bieber will feature as guest on Koffee With Ka...</td>\n",
       "      <td>As per reports, singer Justin Bieber will feat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "78283  I come from a family that used one toilet for ...   \n",
       "771    855 police officers awarded medals on eve of R...   \n",
       "1209   They may kill me, but I feel no fear: Woman wh...   \n",
       "16965  Who is the Japanese billionaire set to be 1st ...   \n",
       "30154  I helped Sara get on board with Karan Johar's ...   \n",
       "97183             World's first cannabis gym opens in US   \n",
       "51986  9 killed as under-construction bridge collapse...   \n",
       "22613  Brazil judge orders to close border to Venezue...   \n",
       "30572  Firm makes Ã¢ÂÂ¹3-lakh iPhone X 'Tesla' with ...   \n",
       "89924  Bieber will feature as guest on Koffee With Ka...   \n",
       "\n",
       "                                                    text  \n",
       "78283  Actor Anupam Kher has said that he comes from ...  \n",
       "771    As many as 855 police personnel were awarded m...  \n",
       "1209   Bindu Ammini, one of the two women who entered...  \n",
       "16965  Billionaire Yusaku Maezawa, set to be the firs...  \n",
       "30154  Talking about his daughter Sara Ali Khan starr...  \n",
       "97183  A new gym where members can consume cannabis b...  \n",
       "51986  At least nine construction workers were killed...  \n",
       "22613  A judge in Brazil has ordered to prevent Venez...  \n",
       "30572  Russian accessory maker Caviar has created an ...  \n",
       "89924  As per reports, singer Justin Bieber will feat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#랜덤한 10개 샘플 출력\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84719a3a",
   "metadata": {},
   "source": [
    "# 추상적 요약\n",
    "## 텍스트 전처리\n",
    "### 중복, 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702585e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "요약문에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "# 중복 확인\n",
    "print('원문에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('요약문에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc4d4b",
   "metadata": {},
   "source": [
    "Summary 열에는 중복이 존재할 수 있지만 Text 열에서의 중복은 제거해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aabc0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8562d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058d8f0",
   "metadata": {},
   "source": [
    "결측치 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be297f64",
   "metadata": {},
   "source": [
    "### 정규화, 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d318c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 정규화 사전 정의\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631c8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 리스트 불러오기\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f0d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=False):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e6363",
   "metadata": {},
   "source": [
    "우선 원문, 요약문 둘 다 불용어 제거 하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32de47d",
   "metadata": {},
   "source": [
    "**전처리한 문장 파일에 저장**\n",
    "```:python\n",
    "# 전체 test 데이터에 대한 전처리\n",
    "with open('news_data_clean_text.txt', 'w') as f:\n",
    "    for sentence in data['text']:\n",
    "        f.write(\"%s\\n\" % preprocess_sentence(sentence))\n",
    "    print('Text Done')\n",
    "# 전체 headline 데이터에 대한 전처리\n",
    "with open('news_data_clean_summary.txt', 'w') as f:\n",
    "    for sentence in data['headlines']:\n",
    "        f.write(\"%s\\n\" % preprocess_sentence(sentence))\n",
    "    print('Summary Done')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f15dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant an alumnus of upgrad and iiit pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad degree career support helped him transition to data scientist at tech mahindra with salary hike upgrad online power learning has powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance to win free food from swiggy for one year pranav kaushik delhi techie bagged this reward after spending cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more', 'new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five match odi series india lost an international match under rohit sharma captaincy after consecutive victories dating back to march the match witnessed india getting all out for their seventh lowest total in odi cricket history', 'with aegon life iterm insurance plan customers can enjoy tax benefits on your premiums paid and save up to on taxes the plan provides life cover up to the age of years also customers have options to insure against critical illnesses disability and accidental death benefit rider with life cover up to the age of years', 'speaking about the sexual harassment allegations against rajkumar hirani sonam kapoor said have known hirani for many years what if it is not true the metoo movement will get derailed in the metoo movement always believe woman but in this case we need to reserve our judgment she added hirani has been accused by an assistant who worked in sanju']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "with open(r'news_data_clean_text.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        clean_text.append(line.strip())    \n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "716fa63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "with open(r'news_data_clean_summary.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        clean_summary.append(line.strip())    \n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43238bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98360"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0192b1",
   "metadata": {},
   "source": [
    "### 전처리 후 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4628a0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Null 값 생겼는지 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1dbf6",
   "metadata": {},
   "source": [
    "결측치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec77fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398761b2",
   "metadata": {},
   "source": [
    "## 샘플 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc14a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 69\n",
      "텍스트의 평균 길이 : 56.180195201301345\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa17372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "434d09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 61 이하인 샘플의 비율: 0.978141520943473\n",
      "전체 샘플 중 길이가 13 이하인 샘플의 비율: 0.9981699877999186\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 61\n",
    "summary_max_len = 13\n",
    "\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ffa89a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 96048\n"
     ]
    }
   ],
   "source": [
    "data = data[(data['text'].apply(lambda t: len(t.split()) <= text_max_len)) &\n",
    "        (data['headlines'].apply(lambda s: len(s.split()) <= summary_max_len))]\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67460908",
   "metadata": {},
   "source": [
    "## 시작 토큰, 종료 토큰 추가\n",
    "디코더의 입력과 레이블에 시작 토큰 `sostoken`과 종료 토큰 `eostoken` 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39696137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit pg p...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india by wickets in the f...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>with aegon life iterm insurance plan customers...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking about the sexual harassment allegatio...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit pg p...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india by wickets in the f...   \n",
       "3  with aegon life iterm insurance plan customers...   \n",
       "4  speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f5d3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 배열로 저장\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c220504",
   "metadata": {},
   "source": [
    "## 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a96583d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 76838\n",
      "훈련 레이블의 개수 : 76838\n",
      "테스트 데이터의 개수 : 19210\n",
      "테스트 레이블의 개수 : 19210\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "encoder_input_train, encoder_input_test, decoder_input_train, decoder_input_test, decoder_target_train, decoder_target_test = train_test_split(encoder_input, decoder_input, decoder_target, \n",
    "                                                                                                                                               test_size=0.2, shuffle=True, random_state=777)\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04aa5a7",
   "metadata": {},
   "source": [
    "## 인코딩\n",
    "vocabulary 만들기, 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d4b5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2882429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69023\n",
      "등장 빈도가 7번 이하인 희귀 단어의 수: 48464\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 20559\n",
      "단어 집합에서 희귀 단어의 비율: 70.21427640062008\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.4555481728192006\n"
     ]
    }
   ],
   "source": [
    "# 단어 빈도수 확인\n",
    "threshold = 8\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12d52ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 내 단어 수 20000개로 제한\n",
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97ef537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4085, 5377, 369, 6414, 612, 14, 75, 273, 3112, 7, 379, 110, 518, 199, 14, 1397, 1, 462, 40, 951, 2380, 19, 1200, 743, 140, 1397, 5, 9288, 1189, 1397, 612, 3, 14, 5728, 3921, 2010, 5, 3070, 1266, 6414, 1231, 178, 2, 336, 4765, 5, 312, 3071, 64, 43, 320, 634, 2094, 44, 5149, 43, 409], [534, 557, 11, 2877, 2, 265, 14, 152, 282, 68, 13, 11, 6, 16, 380, 2, 23, 1991, 287, 3, 776, 6, 122, 1, 557, 11, 3519, 10940, 353, 15, 16, 50, 952, 68, 1, 282, 28, 35, 40, 6, 16599, 1164, 58, 5, 1872, 58, 1, 167, 929, 16, 952, 68, 53, 775, 2, 7097], [30, 54, 90, 11, 156, 6, 3229, 4, 12904, 18, 13, 11, 925, 1194, 3, 1, 1292, 258, 1643, 3, 1390, 3, 758, 17, 12, 1140, 70, 2536, 1, 5051, 4, 1, 1643, 5, 6216, 212, 23, 1073, 1, 11, 925, 14, 23, 19321, 44, 47, 241, 148, 274, 3052, 4, 6276, 111]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43900769",
   "metadata": {},
   "source": [
    "Summary 데이터에 대해서도 동일한 작업 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25af6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72891f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29816\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 19504\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10312\n",
      "단어 집합에서 희귀 단어의 비율: 65.41454252750202\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.708419114760989\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbc6d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 49, 94, 2984, 2332, 273, 5129, 153, 148], [1, 353, 308, 1793, 3, 92, 7, 680, 3, 691, 232], [1, 1166, 20, 95, 1441, 1974, 411, 830, 5, 56], [1, 534, 6, 1590, 2333, 386, 8065, 288], [1, 6781, 19, 4074, 4609, 269, 1258, 3, 5804]]\n",
      "target\n",
      "decoder  [[49, 94, 2984, 2332, 273, 5129, 153, 148, 2], [353, 308, 1793, 3, 92, 7, 680, 3, 691, 232, 2], [1166, 20, 95, 1441, 1974, 411, 830, 5, 56, 2], [534, 6, 1590, 2333, 386, 8065, 288, 2], [6781, 19, 4074, 4609, 269, 1258, 3, 5804, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 내 단어 수 10000개로 제한\n",
    "tar_vocab = 10000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9c0a5",
   "metadata": {},
   "source": [
    "단어사전에 존재하지 않는 단어로만 구성된 샘플은 빈 샘플이 되었으므로 삭제해야 함. 다만, `decoder_input`에는 `sostoken`이, `decoder_target`에는 `eostoken`이 남아있으므로 길이가 1인 샘플을 골라야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "485f1613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 76838\n",
      "훈련 레이블의 개수 : 76838\n",
      "테스트 데이터의 개수 : 19210\n",
      "테스트 레이블의 개수 : 19210\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]    # sostoken, eostoken 남아있음\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e33719",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0407351",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949629d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994ec88",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdbf5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e96e34",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d967b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 61)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 61, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 61, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 61, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 61, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10000)  2570000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,249,104\n",
      "Trainable params: 8,249,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')    # tar_vocab의 단어 수만큼의 선택지 중 하나를 선택하는 다중 클래스 분류 문제이므로 softmax\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f398f90",
   "metadata": {},
   "source": [
    "### 어텐션 층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44aaa7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 61)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 61, 128)      2560000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 61, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 61, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 61, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  5130000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,809,360\n",
      "Trainable params: 10,809,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06b598d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "301/301 [==============================] - 44s 128ms/step - loss: 3.3395 - val_loss: 3.4989\n",
      "Epoch 2/50\n",
      "301/301 [==============================] - 37s 125ms/step - loss: 3.1138 - val_loss: 3.4268\n",
      "Epoch 3/50\n",
      "301/301 [==============================] - 37s 123ms/step - loss: 2.9575 - val_loss: 3.3827\n",
      "Epoch 4/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.8249 - val_loss: 3.3562\n",
      "Epoch 5/50\n",
      "301/301 [==============================] - 37s 123ms/step - loss: 2.7121 - val_loss: 3.3372\n",
      "Epoch 6/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.6094 - val_loss: 3.3251\n",
      "Epoch 7/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.5174 - val_loss: 3.3198\n",
      "Epoch 8/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.4335 - val_loss: 3.3146\n",
      "Epoch 9/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.3565 - val_loss: 3.3183\n",
      "Epoch 10/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.2852 - val_loss: 3.3144\n",
      "Epoch 11/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.2192 - val_loss: 3.3218\n",
      "Epoch 12/50\n",
      "301/301 [==============================] - 37s 124ms/step - loss: 2.1584 - val_loss: 3.3299\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",    # 검증 정확도 모니터링\n",
    "        patience=2,    # 두 번의 에포크동안 정확도 향상되지 않으면 훈련 중지\n",
    "        verbose=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=callbacks_list, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003db781",
   "metadata": {},
   "source": [
    "> optimizer 선정 이유: rmsprop으로 학습해보았는데 속도도 너무 느리고 loss도 잘 안 떨어져서 검색을 해 본 결과, 뉴스 데이터 요약 task에서 adam의 성능이 훨씬 좋았다는 연구를 발견했다. 바꿔보니 실제로 성능이 좋아 adam을 optimizer로 선정하게 되었다 [참고 문헌](https://pdf.sciencedirectassets.com/280203/1-s2.0-S1877050923X00027/1-s2.0-S1877050923002181/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEO7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIBnxlLiNuRRMJ0p%2BhzMniKEJLy6mzghqZ5kSfrj6JhU1AiEAsas7q7u7MMxLWzzvCqkoAvFTti3mPBPRcWClNaZ%2FisUqvAUIh%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDNG4LNOE6HkaPsyYASqQBWoq3gBhFKK8N7uyQESnIJzCqGp9ZuSVjdteREMmI32upwPSnQMgEapIe3%2FObMdqx3DfTAJrckORizz8%2BOEnSJv2NOFKI7v%2FQuqOedVknnUHiF%2BXixZ4VLX22oKEE7NacKZlFdyoNykFyr6ZlyHOAqq6dkozg3TgxQBh4VSWu9G0mm7AdCp9p26oNigYYg%2BKgwnsDqwDMGtNrTZsR3okXdsd3bqdBJmk%2FCcXWPj8tFzSytvi%2FZNMAe0ZdpMr1NzvKTBBpam19SqBGCdWR84PPrA9O8meFSA%2FMg9vsLseOSo7vFmJiTUsV%2FWsErExp2YzO0K4BGkJHtc9Q6Lr4JDUbdBGegYE13DuFanpoiF5DAbMqxNYq1HjJv3YUTFYU9f%2BkMM5dubLkNj%2FYXoztdcnDkSleF3ikeenfjSr85j%2Fl4ZjMaVoS1yCGFfLOsTiQguaeASWTfp9WvR24%2BImKekxV2WiotTee0pk1PS5iXC8cwHHJVTclkQYic31aDVOI3AKoVFNCmZiCWw7BL0skJ%2FeQ6CeHBZ27DppiWhs7jZJ6nuj1eBHn2NqDsBLfpsSdCZbzjeoXQKqMZ%2FeOYYJVeNlJJxa30yfCpKyRB%2F0OFT0eVgAQilVDOsVJrnAsPcr0MpTYzTef0WqJzi6fctPyxI33NdG6vpieRAvLVzyzBzbZpbgcj9JO2gLLCSNuFlstcZMQ73BxWTxX4nmxBDMsRpIx5lxtAiMVqBQDZapo935zTAt1mILyYWxb7c97P79IWwti4Zfytl3sYx8LsOAO9Rq%2BsTyzImMJhsez3C%2B94K9tElUGZ2QOaX4dUAFlKbO8EdQV%2FLLeoKJUZyDQkOqTV94PuQVoyFFaYSFhoGm7UNk4XJjMIKLqrMGOrEB3bctiALMgvHQo3ieA8F6xivo%2F8F%2FqNdnIf2dp0QpF64nJE%2BoEcBeQRTbcgxJInQ7sLU%2FdL71OKEyBl%2By%2Bb%2F%2BP69cTxD%2FFEyBqnbz8KwQcaFgLt0hEigPHNWHKpm9Y6EDtdUxviDn42MHY%2BCC1%2BWyz6UQMLiDINDDVbIkR3Y2MMAoYke5UoVy1CJI0%2FWIBwMweyYxf6kGijgdrmsll9JM5nhM51aPIV9gAHExW1tT3sqh&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240613T063620Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY3TDD4AYJ%2F20240613%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6c903f6dbd94315ddfc5d5e7ba25506771aceb77062e83eae3beeec7b7270f7f&hash=273168d175a47216467ad3417d3e818bcd2519cdd0ffddc71c56684437899031&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1877050923002181&tid=spdf-83bd2b8a-8f1e-4a6b-91b3-0b84e856867a&sid=45137272681506491e99d72907ca641bfe03gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f155e5851575e5f0a&rr=893010d2c9848b64&cc=kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e88967",
   "metadata": {},
   "source": [
    "# Inference Model\n",
    "추론 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야하므로 설계를 별도로 해야 함. 인코더와 디코더 모델을 분리해서 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a259f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8530fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0edf9",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']:\n",
    "            temp += tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69ee21",
   "metadata": {},
   "source": [
    "# 추출적 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize\n",
    "\n",
    "# summarize 내부적으로 토큰화하기 때문에 원문 그대로 넣어도 됨\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))\n",
    "# 출력 결과 리스트로\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))\n",
    "# 출력 결과 단어 개수 지정 가능\n",
    "print('Summary:')\n",
    "print(summarize(text, word=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
