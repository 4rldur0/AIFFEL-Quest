{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695c2eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a3c53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/project/transformer_translator_chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc336c",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13eb31",
   "metadata": {},
   "source": [
    "## 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eda092",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffel/aiffel/project/transformer_translator_chatbot/data/ChatbotData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/1192612408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morigin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/aiffel/aiffel/project/transformer_translator_chatbot/data/ChatbotData.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aiffel/aiffel/project/transformer_translator_chatbot/data/ChatbotData.csv'"
     ]
    }
   ],
   "source": [
    "origin_data = pd.read_csv('/data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = origin_data['Q']\n",
    "answers = origin_data['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f1daf",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe35b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 소문자로 변환\n",
    "    sentence = sentence.lower()\n",
    "    # 영문자, 한글, 숫자, 주요 특수문자만 살리기\n",
    "    sentence = re.sub(r'[^A-Za-zㄱ-ㅎ가-힣ㅏ-ㅣ0-9?.!,]', '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_sentence(\"dk109sd\\]ㅇ마리단./~?!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0aeef4",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "    \n",
    "tokenizer = Mecab()\n",
    "def preprocess_tokeinze(sentence, tokenizer):\n",
    "    # 전처리\n",
    "    preprocessed = preprocess_sentence(sentence)\n",
    "    # 토큰화\n",
    "    return tokenizer.morphs(sentence)\n",
    "\n",
    "tokenized_que = []\n",
    "tokenized_ans = []\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    tokenized_que.append(preprocess_tokeinze(question, tokenizer))\n",
    "    tokenized_ans.append(preprocess_tokeinze(answer, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_que = list(map(len, tokenized_que))\n",
    "lengths_ans = list(map(len, tokenized_ans))\n",
    "fig, ax = plt.subplots(1, 2, constrained_layout=True)\n",
    "ax[0].hist(lengths_que)\n",
    "ax[1].hist(lengths_ans)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b699fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 20으로 설정\n",
    "MAX_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaa716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(arr):\n",
    "    df = pd.DataFrame(arr)\n",
    "    duplicates = df.duplicated()\n",
    "    duplicate_idx = df.index[duplicates].tolist()\n",
    "    return duplicate_idx\n",
    "    \n",
    "def build_corpus(src, tgt, tokenizer, remove_duplicate=True):\n",
    "    # 전처리 및 토큰화\n",
    "    tokenized_src = []\n",
    "    tokenized_tgt = []\n",
    "\n",
    "    for src_sentence, tgt_sentence in zip(src, tgt):\n",
    "        tokenized_src.append(preprocess_tokeinze(src_sentence, tokenizer))\n",
    "        tokenized_tgt.append(preprocess_tokeinze(tgt_sentence, tokenizer))\n",
    "        \n",
    "    # 중복 처리\n",
    "    if remove_duplicate:\n",
    "        src_duplicate_idx = find_duplicates(tokenized_src)\n",
    "        tgt_duplicate_idx = find_duplicates(tokenized_tgt)\n",
    "        src_duplicate_idx.extend(tgt_duplicate_idx)\n",
    "        duplicate_idx = set(src_duplicate_idx)\n",
    "        result_src = [tokenized_src[i] for i in range(len(tokenized_src)) if i not in duplicate_idx]\n",
    "        result_tgt = [tokenized_tgt[i] for i in range(len(tokenized_tgt)) if i not in duplicate_idx]\n",
    "        return result_src, result_tgt\n",
    "    \n",
    "    return tokenized_src, tokenized_tgt      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e954",
   "metadata": {},
   "source": [
    "중복을 제거하는 것이 성능에 도움되는 지 모르겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = build_corpus(questions, answers, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(que_corpus))\n",
    "print(que_corpus[:5])\n",
    "print(len(ans_corpus))\n",
    "print(ans_corpus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c71711",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "https://github.com/Kyubyong/wordvectors?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39033775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 저장된 Word2Vec 모델 파일 불러오기\n",
    "model = Word2Vec.load('./data/ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccea987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(tokens, wv):\n",
    "    selected_tok = random.choice(tokens)\n",
    "\n",
    "    result = \"\"\n",
    "    for tok in tokens:\n",
    "        if tok is selected_tok and tok in wv:\n",
    "            result += wv.most_similar(tok)[0][0] + \" \"\n",
    "\n",
    "        else:\n",
    "            result += tok + \" \"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a415403",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "new_que_corpus = []\n",
    "new_ans_corpus = []\n",
    "\n",
    "new_que_corpus.extend(que_corpus)\n",
    "new_ans_corpus.extend(ans_corpus)\n",
    "\n",
    "use_aug=False\n",
    "if use_aug:\n",
    "    for que, ans in tqdm(zip(que_corpus, ans_corpus), total=len(que_corpus)):\n",
    "        new_que_corpus.append(lexical_sub(que, wv))\n",
    "        new_ans_corpus.append(ans)\n",
    "        new_que_corpus.append(que)\n",
    "        new_ans_corpus.append(lexical_sub(ans, wv))\n",
    "\n",
    "print(len(new_que_corpus))\n",
    "print(len(new_ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_ans_corpus[0])\n",
    "if use_aug:\n",
    "    # 증강된 데이터 확인\n",
    "    print(new_ans_corpus[len(ans_corpus)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86897a1c",
   "metadata": {},
   "source": [
    "## 사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed91082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열을 리스트로 변환\n",
    "def str2list(tokens):\n",
    "    if not isinstance(tokens, list):\n",
    "        return tokens.split() \n",
    "    else:\n",
    "        return tokens\n",
    "    \n",
    "# 시작토큰, 종료토큰 추가\n",
    "def add_s_e_token(tokens):\n",
    "    # 리스트를 문자열로 변환\n",
    "    if isinstance(tokens, list):\n",
    "        tokens = ' '.join(tokens)\n",
    "    sentence = '<start> ' + tokens + ' <end>'\n",
    "    # 문자열을 리스트로 변환\n",
    "    return sentence.split()\n",
    "\n",
    "final_que_corpus = list(map(str2list, new_ans_corpus))\n",
    "final_ans_corpus = list(map(add_s_e_token, new_ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5962f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_ans_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = np.concatenate(final_que_corpus).tolist() + np.concatenate(final_ans_corpus).tolist()\n",
    "\n",
    "counter = Counter(words)\n",
    "print(len(counter.most_common()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb4b36",
   "metadata": {},
   "source": [
    "단어 개수가 많지 않으므로 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d260a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [key for key, _ in counter.most_common()]\n",
    "word2idx = {word:index+2 for index, word in enumerate(vocab)}    # 인덱스 0, 1은 패딩과 unk 토큰을 위해 비워둠\n",
    "word2idx['<pad>'] = 0\n",
    "word2idx['<unk>'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec9e2f",
   "metadata": {},
   "source": [
    "## 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ndarray = [[word2idx.get(word, 1) for word in sentence] for sentence in final_que_corpus]\n",
    "dec_ndarray = [[word2idx.get(word, 1) for word in sentence] for sentence in final_ans_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d8e69",
   "metadata": {},
   "source": [
    "### 패딩 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5014ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(enc_ndarray, maxlen=MAX_LEN, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(dec_ndarray, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_train.shape)\n",
    "print(dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0aa70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)\n",
    "#train_dataset = train_dataset.shuffle(buffer_size=3000, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f4851",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "트랜스포머 - Encoder와 Decoder 각각의 Embedding과 출력층의 Linear, 총 3개의 레이어가 Weight를 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2023c",
   "metadata": {},
   "source": [
    ">**모델 선정 이유**: 트랜스포머는 자연어처리 분야에서 좋은 성능을 내고 있기에 챗봇을 만들 때 사용하기 좋다. 다만, 사전학습된 트랜스포머 모델을 쓰면 더 좋은 성능을 낼 것으로 예상한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0074f59",
   "metadata": {},
   "source": [
    "## positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d488950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccea141",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da412ad9",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd65de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dceeb8",
   "metadata": {},
   "source": [
    "## Position-wise Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22704602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a68b0",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67151f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076e753",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5205b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e654f50",
   "metadata": {},
   "source": [
    "## 전체 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1769028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a991b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "n_layers = 2\n",
    "d_model = 256\n",
    "n_heads = 4\n",
    "d_ff = 1024\n",
    "dropout=0.3\n",
    "shared_fc=True\n",
    "shared_emb=True\n",
    "EPOCHS = 3\n",
    "\n",
    "src_vocab_size = VOCAB_SIZE\n",
    "tgt_vocab_size = VOCAB_SIZE\n",
    "pos_len = MAX_LEN\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, pos_len, dropout, shared_fc, shared_emb)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAD3CAYAAADomBcMAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAC0WSURBVHhe7d1NaGNpvt/xv2+Yfd9cSKTEBSOodId7KRi8sgS9ManlwJSMC0paNbUaipuXwgkEq7yw5Z2pyVsxq6JXkqGMVAOzLCICDZJXZsDcS7pToIEy17qBJL3uges8b0d6ztE50pEsuazj7wfUXbIe6+0c6fmd5/yfx2vXigAAAAAr7s/c/wEAAICVRrAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZwKoIK67/4x/lzR9+K9//+IP7CQAg6qsvvpQXv/i1FL74ufsJgCxixHbFEWoBYDr9Pam/LwFkG8F2xRFqASAdvi+B7CPYAgAAIBMItgAAAMgEgi0AAAAyIX2wvWzK9tqarCVejqTnmt6enhypxz46c1fnMpDm05veBwAgOyb0C9G+8DCu57N90+Q2ytlR/G3mMeL71MHJ9uh+1SX2Oer7ndbG49/n9snA/VRJcz8zPpYR+Z21p031jk+g209rM1Ga7ZFym0WEt8e2NC/dDZ40baaz++ToflK+1xNf1/h9hi5BW7O9/P1R3Wfs9tCP9TmyYNjMI7b13rXoFcLGL3tSdG1WSe8wL9VTdwUAcO8l9wuq435QFWleuX6vK/X9UiQs6M69JOeRNqHA6PQ+1KT+ONpz2sdou2shKmDkKyKNT67f7dWlVowEHB1CiueRNmnCVF26qn3rWc5eTXM/8zyW+R31uodZ4koaUpV8UnDVIV+1n1+a7ZF+m/l0YM1XNsz7pn/vqilSfRAOdmnaTKcDqNon1Tt15e4ndtuPsa+rdtB1r+tauuLvrzmpvHP3512ummV1W1ka37h9c3NP/XyU8XqH6j7dv0POOuqxtj57FrzHpQh6g69Jad9dBQDcc5P7hcHJserQ67IbhD/Vhe+pgCH7nWFQSWrTrryNhJmB9C/KUlh3VzUd+nQQcVfDVLh5rW452JVK8DsqcHQPRGofho+e0KYt1W9niVJp7me+x9JhXlTQ2tt0P9Dh6nVDyqdVeRsJaWakMynkp5Rme6TfZr6evK20pdx8PgxyuWdvpLFTk+NhIE7TJoXLjrROVdB8XVHvlhNs+9fJI9nB6+q+GkXN4isb2hMDsTqQeGGe85vRdk1p0D+X8sOCu/b5LCXYmp1RHX31QsPvcUco9ktk4W2mnkLQ7dWXx446+vmkPlDupyHmVNC8pwwAAKslRb+QQv+jimHRUavNLRUvatLxw4QOK7ItW0F4cCOZ5eaVGzGbR1/6pzI2Clx8HA7f06W5n3SPFeSBIHwVX13LtRe0jPWCbLh/BuxIZ9uM7OoAl57NA0FwS7M9Um2zaCa47IuKcbL99TBqKjnZelKW9vuOfb1p2qSxXpHWdWssaBYeTt5PYl+XFKSwI3Lej3/03rfqQEJ9Bt4MQ75iDrh09tIjx+7ATx2I5EMZaSCd9+K9Vtt2lN3Slk7c3PJGbNWLLr3fHg6bdw9qUvJDqdlJIkPkCW1Gpwf0EPl5uI1SKx5LwTsVIpOORgx1NKbbvvOOfqISdiQAQBZN7xdyz3ZN2PFH5I70afJheNCjsJI4auWHicF3LZEnW6ERON2HDUsBxuSk8lL3b8ejMKEChw4Zw3DpglRoFHjoXPppB2rS3E/Kx8o9a03uazV9CjtyX+b31PsxGtmdzARoE6BsHrC/l2Z7pNxm0UygXn9bxfHY13+qQr/+f5o2c9NBUgXXR4XJ722C9seYR1eZ61jvTy+TtpctXTAHGvoAMPR++AdqOtTmpfpolO/Sl8Tc3MzBVtd0+Al8eBkbJQ0Pm5vhb+8LITgquIoOkXtt9Ac/euRgd/ZwPW9oyHzzuTTU0cjo1AwAAIugw++VbL/Pu77PDbxERyBT0KNpG4UZI4kOv5+2pfXA9buuvjVt+LubXEnDThCKZjE6W5v/uOtC1D0ZkDp7a+rAx2u0R8yI7thIvR1pj2NymUphW/PsTzrED0O2fYzQwYI5cLudbbO4yWPRD/bYTlqULZXy7VGCPUIaP9JwbcwQffqjkZm/HAAAmJU5JZuX/sug73Mhd+YZ+z3p7M8eIHqHKsQ96Mtu0O+6kDttktNdZifqRepH0zDbwjtbO8fBxcrSZ7PNmQK/Vnlc7uttKUtNSt7AY+LEL7NP6oHCUT3wLMITIV2Wq8zz2bi5zzp5LE2RcZo2AAAsVzBZKt3Ep4nmmT0enCbueWcs1yvyplmeMsnp7tJBvbSvQu2nOUbyzAjgrvSD0eupc2syQodaPaFOl3FOC/O6fELXi++X7HukLp3HV+as9hhXDhKuB05r/EBN11KbWnFTi3u72+gWg60bpfXE1nho3ihtYhsAAG7Z2GCLm/hkazFzUniU3G8FZxfnnz0+XtOaK5hHtzWt5rm0E2ppE2o946S5nxs+1o1C7ZCri1aXq4fHLrz5dZxptke6bTZGvf6yV0scslMQs3XTtJnFLKE2YGqD3ai2uuxtxpQJKHqfnGkf8el665jXE9RJm+2jQ26KJdQWYYmTx1rSCW1M+2baoWq7I8lFPzJE7YbCzRue1AYAgM9jWgCKrWs0o2HBiFZ09vgspgVJO+M9OsfELrE1ywhxmvuZ/7EWE2rDRiHKjuIGE8inb490bca4YN/6zk8otoSyHEwKTNMmrTlCrZ1QF1lJKmFkNn4FhXTGJkLG0NtHTzq7jcHKJY7YtqX6clRbYeo6dhry3O0kxW/s6Zv8WO3HaC25oM0LP+GbuhqW4QIA3KZgVQJ/1R09+zvctwUrJ4zqGu3KCcPaxegyX2mtV2RXBYNaMbJykH/fcc/RrJygQmSw2H4qae5nvsfSYWvRoTbMjuIG5SJTt4eSps24ojw3ZSAvhnlkcPJCqqfh9XCnt0lDPZ9ZR2qVoMZ2fBUPb+1hY/LKEJPFHaipx1mL1H4HpTQTJrstyszBNnFVBHUZfdi1ujSetIa1FaWLhlz5S36Y4XG7UHDw+6aNv+KBa7OhC5BdGzsL9BZm1ukvDAI0ACBgViVoyPmwH8zbvwYVWs5KByu/b7PLWg6X8QrNHp+NrVvUS166x1dhR/8VtNASYfo5mqWVXBsVZOq9OWtYp91PijbhdWztHywwA19Bbax3Wc5p6inbw0jRJiYT6FFI+5fE7PO3fxUuvGpTmjZmUuCE+lP7hxYULy+NLqMDnfB7rbgaWxlmqKRVPJJXSogzHJhU93l0pn83WsJg389QdnP76rA+fYkZa+1aj90vmH5z7Z+QC288LN4vf/fE/QsAMM3vf/Xe/QsB+uzPrSdHhyJ7M4zGZsHg5Eg6X+8tfKDys66KAAAAcK+ddeR8rjKAVWZLGOaarDYFwRYAgHtP/+XP1V4Td1X1PpzPOZlwhela80fzTVabZimlCLg9lCIAQHqUIgDZxojtCvuHf/gH9y8AAAAwYrvC9KZ7+d//vXz/f39wPwEAJPnqz7+U3zw+dtcAZBHBdsX9zd/9rfzn7/6rfPw/H91PAABRX/6TL+Xffv2v5V/+06/cTwBkEcEWAAAAmUCNLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgE+YOtr3DNdk+GbhrYYOTbVlbW3OXbWleuhs8U9ucHY1uP+y5HwYG0ny6Jkdn7ioAADdh+pz4/upe8/vip03V+wJ321zBVofS0r67EqFvy1c2pHt9LdfqctUUqT44Ej+aTm/Tk6NiTeo9ffuVNC5K4RB99laqj7qyt+muAwCAxdvcM/1098BdB+64GYOtHSnNV9ruelRP3qrbys3nUnQ/yT17I42dmhwPg2mKNmcdqUlZCuv6Sk4Kj0TaH/vmJvMcXp9L45vgtwEAAICZgq0OtXmpntale92VuvtpyGVfzlUg3f46536g5WTrSVna7zv2FEaaNpOY0dpdqZjQCwDALbpsynZwaj729LwdABreri7RsjldyuffnlTWl8w+xvZJL/xYMaUC0ceKtjFlgepnvWnlgcCKmCHY5qTyTpcG7A1HWseo0NqWDTfSGnHaFzPmmqbN5pYKzm3pmw/WQPoXIuWHBfNvRmsBAJ+Frjd9UBVpXpnT86ZUTqqSH4ZFNwD0qOtuV5deXWrFUVDUQbN00ZCr4PZPDZFKfhh+x4Jo6BIu62tXStJ/Obqf8mlVXngheeyx9KCUapOPzltRPyt93HVt1GvaaUv1JfW0WE1zTx5brqLsmS8D/UG2XxKtZzlGawEAn4keWKmJHLj+yMhJ5bUNlG9NMO1L/zQYiHFMjWrL9Vt2oEYeFdRvOusVaalAGcwZKb4KQmjcJTKwpJ7LcK6Jup/dAxV2h2c+e9LZF6m/rIweS/32lq6VvehHQmtduq+GxYFSeVlXYbclHUZtsYLuaLBVXMG6uZgPnP5SEffh68lRwhEsAACLFxNatfUt2d4RqX3QPZENju1KPmEFAVt2J/ulhfRdY88lpCh7qv+0wXfUZ8ZO/N4pyKR7AlbJ3Q22EYOTF9J6Yiec9Q5LUlNHqjr0XjXPpRT7BQIAwGJtFPz5IeP0iOtVU4VXfco/GIDxTv3nnrVMeYKKwlIKbl9SHzYqa1B95o4tSWB1A2TdYoPtekHKcu5qYyOCI8I0bcbolRQ2ZNec/rGnV4Ij1VxhY1SbCwDAEp334yOoP3pqwqs742hC7n5kyUr/jKQOuV7d6yw1thNdNuVYlyKYZTPV5Z1fkgBk18KD7Ya0pfWd/8EfSOd9W8pPtuyHKk2biMHJsZx7y4Np046aAQBYnIIUdvylJ53LjrROk/skHXL1KOnY7wVUyDXh19W9zlRjO4mZqF2XrdB673ZgCMiyBZciFOW5+oC2Ky+GM0B1CYFeIsyOtmpp2vj80VrN1jDZeib1u/1z6oMAAEvmJlWFRl8H0nxZlfZOQ557tayh0dlg5PSxmyuil+cKrUrg1nZPGNiZmzk76q8hr0eDS+onCmc5kWELr7HVR6f2L4nZUyf5ikjjU/goM02bgP4gRkdri6+6UjfF9/p3N6TLKRYAwI21h/1S6BLUwOoSArc8l73NLe017IP0hK2ubAxvVxe3PJidxKWXzbR/TXN4u65/Da20sCB6tYVe3U5kc49Vkq4dHU4qBwQyYO1an98AAABIMFwTl4Ek3HErsyoCAAAAMAnBFgAAxNN/bU2XMTDpDCuCUgQAAABkAiO2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgEwi2AAAAyASCLQAAADKBYAsAAIBMINgCAAAgE9auFfdvrJj+j3+UN3/4rXz/4w/uJwCAr774Ul784tdS+OLn7icA7gtGbFfUn/70J0ItAMTQ34v6+xHA/UOwXVE/+9nPCLUAkIDvR+B+ItgCAAAgEwi2AAAAyASCLQAAADIhfbC9bMr22pqsJV6OpOea3p6eHKnHPjpzV2cwONkOP//D23/2AIDPr3e4JtsnA3fNZ/uYYT/xtCnjrQbSfDqtjXJ2FN/PmL41vv+M9lOxfZ2+32ltfH5fHnqukdca2yemaTOBfq5p3sMb5Yklvo407/Ws22OaCfuHT+/DiftegsT9PiHvjV6Lff/819Y73JbmpbsypNvdfjacecS23rsWvULY+GVPiq7NXae/LPIVkcan4Ll3pb5fmv1DCgBYabo/KO27KyE6bJWkdtB1/cSVNKQq+VB40G3yUn0UaRPTl/Q+1KT+ONpLqo7/QVXa7lqICkihfqpXl1oxEpR0iCqeR9rEBYxxpi9/V5GcuaYDSEnOm1fuddg+MRx60rSZQIelYs1dCesdqvdQvXNX5n6vpXtQk9JcgWiJryPNe32D7RFvwv7hU48bvw8nS97vlcu+esy6dM37M7rsbbrbVdrb868nPf5ZR31+tm49G97DUoSBdN63pdx8I5V19yO9kdQOKPvHN9gBAQCrw44S5isJseHsrVRPy9L4JuiWc1J53ZDyaUs6QT+R1GasLxlI/6IshWGfo+gQpAJWfNRTz+21uuVgd9RPbe6pwCdS+xDEvaQ2bal+O1skHJwcq+dRl91nNuYGfWK78nYYLtO0SWJGnpMCmgq8xyoU1V8GIVvd8ysVNtWjdWYc7Vze60jzXi9uexgT9w+fCr8JBwzxpuz3yqB/LrJTkIK7Pi99P+WHN72X2S0l2JqdWB3V9vT/h8PYcUdf+sjJH+peUJuJI6/qi+fdtbSGO7WzXpCy+6dhhuJvcqQFALibdOeeV6FUj0rpEDUfGwC2ZcsPrOtbsr3TltZ33gjgZUda4rUzI3s1KTev5KoZ6nlm0Jf+qQqEkVHg4mM9SNOJ6SeT9T+qkBMdWdvcCoXLNG3i+k17hrRtRoh1MB+zXpFWaDRQueyLemdTsH1/MIq9sNcRud907/Xitscs+0fv0J5ViH1vx6Tb7/V7VH6yNTzQGDd6f0zeM8FaBfgHfmmDHkQU2f46uBcbqEdZLnL2YYGWN2J7WpXS++3kUwvmA+Cf5kluMzplcK028vnYKYpa8VgK3tC/7JdmfsMG37XUZtkYHVGbD1vLG9UFAGSDHeCYWEK3+VwaKqCGRuReVqXtBVkTkh4VYgNA+2Pf/cv2L+IHhc0901+NDbAMqef3Uvdl3sivO907DE4m/EVGgYfOpZ96UEaPJkviyNp5XweVNG2UmH4z96xlXmsouE7R+1a/zw15nvA7JkyZcGT7fnvfC3wdaq8InWpP814vbHsoU/cPx+wT/hmDaVLs9ypdddR+1q7kU4VQs3117lKvXZdgDJ9z6GDOBephyY7Najcr00g2c7DVNT7+ix1exkZJ1Yt8PX5q4dil+WDHvXo1enujbUzYVG3eeBvXfkjCGyVUVmC+jPzTNWn05K0elv8MtSAAgLvIhoCulFw/5zrmYV1qejoAbxRm/C0dbj5tS+uB62Nd7eYsAXHVBIHVBHivNMEanZnNf9x1Aek+Dz6psPhaj+r6ZZULEIyWe4OONoTOOMKq7qc9POizo9mhAwoT3pez/RY3ecwLqEb09IyKjFsHwVGsPWoaP9J1bd53VAtbC5t0NOyb+QsjRB9J6DqWunSjrwEAcD+ZM4ZrcvxwdMbQhty4crhJ9AhYXbZmDKRmlvuDvuwGfawLuakna62gYHRXT+gSFaSGr9XUm3pnZumr1UHACzPhzh/4WwhXGhJ6j02tsEjtdfpVF8KTJV2206PAM67cMI/POnks6XSAL02b+bnhcVNvsjqrOgAAlis4q+gHh+hZxVTmmRmuQrWZUNXz+iUVON40y6kma62+ojz3X6sZ3duVfjB6fd9XMFL7xwu9YoZ3VnzZCg/LIqd9GRXYTDJ+MFd8pUtJ9X1UJe9G3pe1HW8x2LpRWo9fgxTijdImtrkxQi0AYIKxM4YFKeyM+iXT2V/0Y0eggkGZ+WeGj9dr5gob6r+uXnO9IBvSTqjd9OaLTJWTwqPkvtaeEU3TZtls3asesb16eGyDUWii2hJfR5r3emHbYzo7J8hO1rLvgy3fsKHxDkx61+UMMasqjEbkXcidZbm4GSxx8pi3JIrhzxi0O9f4F4ItWrZfAkltFoFQCwCYYkpoNUEz2tfpSTOnZTcbPDozfBbTQpIN2dH5JPoU8KzzRUxAj87c1yPNMhp1S9NmLqbMYDyMmYl5CUtOjQKSHcUNaj+X9zrSvNeL2x7T+AExuJhVEfS8pZvWrU7aHilfx9hkyRj6NejnnHSQcRNLHLFVRxMvR7UUZkkKb5Zj8Ru9HmB4IWvTRu1cwfpyQZsXfqJPeNNnYRaDJtQCABLE9T9B3zFcAzVYOWHY1w3sygnBWqbRZb7SWq/Irq5pLEZWCTJLQD13/VawcoK3CtDMs+St3LNd1fPWpDTsj3tmbdTRY6VrM5ex91AxryNuAllUePWC5b2ONO/14rbHZxWzPfSkvvSvI+5gzk78C43OBuU2wzrcxZk52CauiqAu4RlzdWk8aQ1rKUoX6kjCn01qCpS79i9++W38sOnabPjLTpiZoTc4InFvpnolUgru07sMX4P+ErkLQ/oAgNsX0/+U9qMDInrlBPfXxkwbFXz1X9AKJt6EZobPxtYk6uUtXf/0oCrSvAovAaVrT92MddNGBbR6b57+UQdEvz+2S3GGl5tK0WaufjP6HurXMe8KEAt6HS6IhTJNmvc6RRuz8sMtTKDS5nus8e1h/wLehP0qCMO6NOLw99I/jZZe2Pc8lOXc/jzaxjHv+ZzWrvUY9oLpNzNf2WBEdMl++bsn7l8AgKjf/+q9+xeGdPhUoWKjl+2lw+6ugTQPO7L16vYmfq2MsyM5kr0b75efdVUEAACAe8OUp8w3ip91vQ/nC5lkR7AFAOCeMafLb+mUOEb0xKqNJdSVrr6edC7mqEePsZRSBNwOShEAIBmlCMD9w4jtivrpp5/cvwAAAKAxYrui9Gb7dx925Ycf/5f7CQAg8NWffym/eXzsrgG4Lwi2K+xv/u5v5b/13sj3f/+D+wkA3G9r/+jP5F/8xUP56+IL+at//pfupwDuC4ItAAAAMoEaWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJswdbHuHa7J9MnDXwgYn27K2tuYu29K8dDd4prY5OxrdfthzPwwMpPl0TY7O3FUAANK6bMq26lvoQyL8fvdpU/W0wOqZK9jqUFrad1ci9G35yoZ0r6/lWl2umiLVB0fiR9PpbXpyVKxJvadvv5LGRSkcos/eSvVRV/Y23XUAAHAzm3umT+4euOvACpox2NqR0nyl7a5H9eStuq3cfC5F95PcszfS2KnJ8TCYpmhz1pGalKWwrq/kpPBIpP2xb24yz+H1uTS+CX4bAAAAmCnY6lCbl+ppXbrXXam7n4Zc9uVcBdLtr3PuB1pOtp6Upf2+Y09rpGkziRmt3ZWKCb0AACxLT46CU/PmEj77qOmyvNHt4yV6025Pw5TuPW1Kb5YSvpg2qe8HWGEzBNucVN7p0oC94UjrGBVa27LhRlojTvtixlzTtNncUsG5LX3zYRtI/0Kk/LBg/s1oLQBg6UwdbklqB11zet6eoq9JyQu3OrSWLhpy5W6//tQQqeSHtbvTbh8PouFLqAb4tCqlj7vuuVxJY6ct1ZdeHay+r6LqHz+5x1KX7oFqEykFnHo/wIqbe/LYchVlr1eXWlF/uPOmnrb1LMdoLQDgVvS+rUp7R4XSV6OBlOIrfbYyKJuzgy7yqCDD84/rFWmpwGjnf0y7XXE1rUmX8DySunSHzyUnlZd1FVJb0nGjrb0PNZGDcP9YfKzPrZ67QaLA5PsBVt0dDbaK/4E3H0I9WivuA+mfHho/NQQAwPxiQqlRlK0DcWVztoRO9ksJ/dC022e0UxB93jJJ8VXQV9qRYtM/FlXYjZpyP8Cqu7vBNmJw8kJaT+yEs97h6PTQVfNcSixLAgBYMFsClyz3rCXXPT0qqksUXJj0+qNpty+UV9ZQ2i/bkgTz2MD9sthgu16Q8thpDyc4SkzTZoxeSWFDdnU5gvp3Z3/0hZMrbIxqcwEAWJDRajwR/kiuf3ZRB8nTquT9tdcn3T5Lje1E+oymLkUI6oFblOzh3lp4sN2QtrS+849HB9J535byky37RZCmTcTg5FjOveXBtI1CXEsAAG7KLjMpF/3I6Gp4YGWMCrFXzXLM7znR2/3QG3NJv1Z7X/qnIvXHfi+pnq2uuwXumQWXIhTlufrQtisvhsuH6BICvUSYHW3V0rTx+aO1mq1xqn2wR7yD/jk1QwCAhSp+05ByZPTVlMFJ0FfpJTDXIn8Z063TbgZppt2+SKoP3FH94uvwKgn2DykFKwwB98PCa2x1TZH9S2L2VEq+ItL4FF4iLE2bgP4iiY7WmpmppiBf/+6GdN9VFvwlAQDIOrvyTvTiJnqZFQxGfY2+2KW7gr5KL4Fp/zLm6Hft/A+zis/U2xdJP5Z6rjqIB4+lnmT3kwrn6tbzfuz4MZBJa9f6fAcAAIAyXH+XQSOsoJVZFQEAAACYhGALAACGqzTY2lxgNVGKAAAAgExgxBYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGQCwRYAAACZQLAFAABAJhBsAQAAkAkEWwAAAGTC2rXi/o0V0//xj/LmD7+V73/8wf0EAPDVF1/Ki1/8Wgpf/Nz9BMB9wYjtitLHI4RaABinvxf19yOA+4dgu6LW1tYItQCQgO9H4H4i2AIAACATCLYAAADIBIItAAAAMiF9sL1syvbamqntjL8cSc81vT09OVKPfXTmrs7i7Cj0/LdPBu4GAMB90jtM6gNsHzPsK542ZbzVQJpPp7VRdJ9zGNNLmr41vv8cnGyP7lddYvu6SF82tT/0+/LQc4281rjnmqrNBPq5pnkPb5Qnlvg60rzXs26PaSbsHz69DyfueyEp99dA7Daz75//2nqH29K8dFeGdLvbz4Yzj9jWe9dmRv74ZU+Krs2dp3eUYm30Wj41RCp5wi0A3DM6PJb23ZUQHQBKUjvouj7uShpSlXyok9dt8lJ9FGkTE5R6H1Sf8zjaS6qO/0FV2u5aiAoU+YpI45Prp3p1qRUjQUmHjuJ5pE1cwBhn+r93FcmZazqAlOS8eeVeR1fq+6VIn5imzQSu343TO1TvoXrnrsz9Xkv3oCaluQLREl9Hmvf6Btsj3oT9w6ceN34fjkq/vxqJ26woe+r39zbd1aTHP+uoz8/WrWfDe1mK0PtW7Sg7DXkebJT1irxplqX9vhM5KgEAZJMducpXEmLD2Vupnpal8U3QLeek8roh5dOWdIKgktRm/zgSZgbSvyhLYd1d1XQIUgErPuqp5/Za3XKwK5Xgdzb3VOATqX0IQkhSm7ZUv50tEg5OjtXzqMvuMxtzTXBRoaxdeTsMl2naJDEjz0kBTYWnYxWK6i+DkK3u+ZUKm+rROjOOdi7vdaR5rxe3PYyJ+4dPhd+EA4YxqffXKdsspUH/XMoPC+7a7VlKsDVviDqq7YVOo8QdfekjJ29IfFFtppxWKL5SRyrDI1Wr/zGy+czw/02OtAAAd5MOtXnVydelq0fs3E9npTtu2dmWLT+wrm/J9k5bWt95wySXHWmJ186M7NWk3LySq2bZ/XBWfemfqkAYGQUuPlavZr8T008mM/1fdGRtcysULtO0ies3dR7QBw96hFgH8zHrFWn5o3/aZV/UO5uC7fuDUeyFvY7I/aZ7rxe3PWbZP3qH9qxC7HsbkXZ/nbrNvPfH5D0TrFWAf+CX9Ayk815k++sgaenPnJfTQu/vYi1vxPa0KqX328mnFswHwD/Nk9xmdMrgWm3k87FTFLXisRS8oX/ZL832hsUcMdoPW2t05AUAyIicVN7pPmNCCd3mc2moDj80IvdSn+0bBQMTkh4VQoMkgfbHvvuX+s3vWiJPtkbtNvdMf9UajhpGqef3Uvdl3kiaO907DE4m/EVGgYfOpZ96UEaPJkviyNp5XweVNG2UmH4z96xlXmsouE4xdlY1woQpE45s32/ve4GvQ+0VoVPtad7rhW0PZer+4Zh9wh+BnSzt/jrLNjNtde5Sr12XYAyfc+hgzh1IDksgbFa7WZlGspmDra7x8RP38DI2Sqpe5OvxUwvHLs0HO+7Vq9EGibbRXwa6zRtv49o3PPxlVG6+8Yb+9ZeRf7pmEjfSq4fbJ3yIAAD3jQ2/XSm5fs51zJGzfWnoQLFRmPG3dLj5tC2tB66PdbWbswTEVRMEVhPg/YEmY3RmNv9x1wWk+zz4ZEsfQvnnLlFBvz0M0XY0O3RAYcL7crbf4iaPeQHViA53qyi6dRAcFdijpvEjB9fG1LrqYezkowvfzF8YQ/aoTD//qyctyceWOQAA7h1zxnBNjh+OzhjakDtrP9GTzn5dtmYMpGaW+4O+7LrHDkJu6slaKygYKdQTuqTovVZTb+qdmY3mjXtocPLCTLjzB/7ukvBkSZftKvmUKzfczGedPJZ0OsCXps0i5J7thkaLAQD3V3BW0Q8O0bOKqcwzMzwoj+t5ZyeDSc4pJmutvqI891+rGd3blX4wep12ea6sUvvHC71ihndW/G4ZP5jTc5tMvfBpVfJu5H1Z2/EWg60bpfX4NR0h3ihtYhsAAJZp7IxhQQo7o36p8FB11Bf92BGoYFBm/pnh4/WaucKG+q+r11wvyIa0E2o3NxJqPePkpPAoua+1Z0TTtFk27wzrw2MbjEIT1Zb4OtK81wvbHtOZMk03Wcu+D7Z8w4bG5LrVNPvrQuh64x31WXFXA6MReRdyZ1kubgZLnDzmLYli+DMG7c41/gbrlB+8wUltbsrNzIseKZjC79v6gAIA7rwpIcAEzWhfpyfNnJbdbPDozPBZTAtJNmRH55PoU8Bjs/6nMIEnOnNfjzTLaNQtTZu5mDKD8TBmJjrFhCNtFJDsKG4wWXx5ryPNe7247TGNHxCDi1m9QM9bmlC3On1/XYyxyZIx9GvQzznpIOMmljhiq44mXo5qKcySFN4EreI3ej3A8MLApo3auYL15YI2L/xEn/AhSC+YbeqvnBDMdmUCGQAgvv8xf0jg1FsDNVg5YdjXub4kWMs0usxXWusV2VWdfq0YWSXILAH13IWkmL5sxlnygaAUrzTsj3tmbdTRY6VrM5ex91AxryNuAllUePWC5b2ONO/14rbH0kzbXxci7mDOTvwLjc4G5TbDOtzFmTnYJq6KoC6joKjVpWEmZNnbShfqSMKfTWqWBemav/gR/L5p46944Nps6IJj18bODL3hTDpdr2OWmnD3GTfb1UwcWM5SFACAOy6m/ynt63Vv/VV59MoJ7q83BX2J/gtaweSm0Mzw2diaRL28peunHlRFmlfhJaCifZkKaPXePP2jDoh+f2yX4gwvN5WizVz9ZvQ91K9j3hUgFvQ6XBALZZo073WKNmblh1uYQKWNP9aU/XVeQWDWpRGHv5f+abT0wr7noSzn9ufRNo55z+e0dq3HsBdMv5n5ykbkCwCL9svfPXH/AgBE/f5X792/MKTDpwoVG71sLx12dw2kediRrVd3deLXZ3R2JEeyd+P98rOuigAAAHBvmPKU+Ubxs6734Xwhk+wItgAA3DPmdPktnRLHiJ5YtbGEutLV15POxRz16DGWUoqA20EpAgAkoxQBuH8YsV1RP/30k/sXAAAANEZsV9Sf/vQn+Q//4z/K9//vB/cTAEDgq3/8pfzmXx27awDuC4LtCvuff/+9/Kfv/ov88L8JtwAQePgXD+XffP3X8lf/7C/dTwDcFwRbAAAAZAI1tgAAAMgEgi0AAAAygWALAACATCDYAgAAIBMItgAAAMgEgi0AAAAygWALAACATCDYAgAAIBMItgAAAMgEgi0AAAAygWALAACATCDYAgAAIBMItgAAAMgEgi0AAAAygWALAACATJg72PYO12T7ZOCuhQ1OtmVtbc1dtqV56W7wTG1zdjS6/bDnfhgYSPPpmhyduasAAKR12ZRt1bfQh0T4/e7TpuppgdUzV7DVobS0765E6NvylQ3pXl/LtbpcNUWqD47Ej6bT2/TkqFiTek/ffiWNi1I4RJ+9leqjruxtuusAAOBmNvdMn9w9cNeBFTRjsLUjpflK212P6slbdVu5+VyK7ie5Z2+ksVOT42EwTdHmrCM1KUthXV/JSeGRSPtj39xknsPrc2l8E/w2AAAAMFOw1aE2L9XTunSvu1J3Pw257Mu5CqTbX+fcD7ScbD0pS/t9x57WSNNmEjNauysVE3oBAFiWnhwFp+bNJXz2UdNleaPbx0v0pt2ehinde9qU3iwlfDFtUt8PsMJmCLY5qbzTpQF7w5HWMSq0tmXDjbRGnPbFjLmmabO5pYJzW/rmwzaQ/oVI+WHB/JvRWgDA0pk63JLUDrrm9Lw9RV+TkhdudWgtXTTkyt1+/akhUskPa3en3T4eRMOXUA3waVVKH3fdc7mSxk5bqi+9Olh9X0XVP35yj6Uu3QPVJlIKOPV+gBU39+Sx5SrKXq8utaL+cOdNPW3rWY7RWgDAreh9W5X2jgqlr0YDKcVX+mxlUDZnB13kUUGG5x/XK9JSgdHO/5h2u+JqWpMu4XkkdekOn0tOKi/rKqS2pONGW3sfaiIH4f6x+FifWz13g0SByfcDrLo7GmwV/wNvPoR6tFbcB9I/PTR+aggAgPnFhFKjKFsH4srmbAmd7JcS+qFpt89opyD6vGWS4qugr7QjxaZ/LKqwGzXlfoBVd3eDbcTg5IW0ntgJZ73D0emhq+a5lFiWBACwYLYELlnuWUuue3pUVJcouDDp9UfTbl8or6yhtF+2JQnmsYH7ZbHBdr0g5bHTHk5wlJimzRi9ksKG7OpyBPXvzv7oCydX2BjV5gIAsCCj1Xgi/JFc/+yiDpKnVcn7a69Pun2WGtuJ9BlNXYoQ1AO3KNnDvbXwYLshbWl95x+PDqTzvi3lJ1v2iyBNm4jBybGce8uDaRuFuJYAANyUXWZSLvqR0dXwwMoYFWKvmuWY33Oit/uhN+aSfq32vvRPReqP/V5SPVtddwvcMwsuRSjKc/WhbVdeDJcP0SUEeokwO9qqpWnj80drNVvjVPtgj3gH/XNqhgAAC1X8piHlyOirKYOToK/SS2CuRf4yplun3QzSTLt9kVQfuKP6xdfhVRLsH1IKVhgC7oeF19jqmiL7l8TsqZR8RaTxKbxEWJo2Af1FEh2tNTNTTUG+/t0N6b6rLPhLAgCQdXblnejFTfQyKxiM+hp9sUt3BX2VXgLT/mXM0e/a+R9mFZ+pty+Sfiz1XHUQDx5LPcnuJxXO1a3n/djxYyCT1q71+Q4AAABluP4ug0ZYQSuzKgIAAAAwCcEWAAAMV2mwtbnAaqIUAQAAAJnAiC0AAAAygWALAACATCDYAgAAIBMItgAAAMgEgi0AAAAygWALAACADBD5/3xgMm5hE6xgAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "67b31c13",
   "metadata": {},
   "source": [
    "```\n",
    "n_layers = 2\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "dropout=0.3\n",
    "shared_fc=True\n",
    "shared_emb=True\n",
    "EPOCHS = 3\n",
    "```\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "```\n",
    "n_layers = 2\n",
    "d_model = 256\n",
    "n_heads = 4\n",
    "d_ff = 1024\n",
    "dropout=0.3\n",
    "shared_fc=True\n",
    "shared_emb=True\n",
    "EPOCHS = 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24e852",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513cd9f",
   "metadata": {},
   "source": [
    "## 학습률 스케쥴러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8a488",
   "metadata": {},
   "source": [
    "## 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3348d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef82c23",
   "metadata": {},
   "source": [
    ">**loss 선정 이유**: SparseCategoricalCrossentropy() 함수를 사용해 단어장의 단어 중 선택하는 다중 클래스 분류의 loss를 활용함. 또한 loss_function을 따로 정의하여 패딩에 대한 처리를 해 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b78c8c",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a853f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    dataset_count = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    tqdm_bar = tqdm(train_dataset, total=dataset_count)\n",
    "\n",
    "    for i, (enc_train, dec_train) in enumerate(tqdm_bar):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "                                train_step(enc_train,\n",
    "                                           dec_train,\n",
    "                                           transformer,\n",
    "                                           optimizer)\n",
    "        #print(i, ': ', batch_loss)\n",
    "        if np.isnan(batch_loss):\n",
    "            # input에 nan 값 있는지 확인\n",
    "            print(pd.DataFrame(enc_train).isnull().any().any())\n",
    "            print(pd.DataFrame(dec_train).isnull().any().any())\n",
    "            print(enc_train)\n",
    "            print(dec_train)\n",
    "            break\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        tqdm_bar.set_description(f'Epoch {epoch + 1}')\n",
    "        tqdm_bar.set_postfix(Loss=f'{total_loss / (i + 1):.4f}') \n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "848b41b0",
   "metadata": {},
   "source": [
    "마지막 batch에서만 loss가 nan\n",
    "![image.png](attachment:image.png)\n",
    "- input에 nan 있을 수 있음 -> 없음\n",
    "- batch 크기 1로(batch 크기대로 자를 때 마지막 남는 데이터는 앞의 데이터와 shape이 다름) -> 해결 x\n",
    "- augmentation 없애기(중복값이 너무 많으면 loss가 NaN이 될 수 있음) -> 해결 x\n",
    "- 특정 배치에서만 일어나기 때문에 shuffle 사용해서 결과 확인 -> 마지막 batch가 아닌 곳에서 loss nan(seed=123일 때 92번째 batch, 124일 때 47번째 batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6c4ce",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bac043",
   "metadata": {},
   "source": [
    ">**metric 선정 이유**: BLEU score는 번역 task에서 가장 널리 사용되고 있고, 다양한 측면을 고려할 수 있기 때문에 적합하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec831ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tokens, model, word2idx, idx2word):\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=MAX_LEN,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([word2idx['<start>']], 0)   \n",
    "    for i in range(MAX_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "        if word2idx['<end>'] == predicted_id:\n",
    "            result = [idx2word.get(idx, '<unk>') for idx in output]\n",
    "            return ' '.join(result)\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "    result = [idx2word.get(idx, '<unk>') for idx in ids]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, word2idx, verbose=True):\n",
    "    idx2word =  dict((k, v) for v, k in word2idx.items()) \n",
    "    src_tokens = preprocess_tokeinze(src_sentence, tokenizer)\n",
    "    src_vector = [word2idx.get(word, 1) for word in src_tokens]\n",
    "    tgt_tokens = tgt_sentence.split()\n",
    "    if (len(src_vector) > MAX_LEN): return None\n",
    "    if (len(tgt_tokens) > MAX_LEN): return None\n",
    "\n",
    "    reference = tgt_tokens\n",
    "    candidate = translate(src_vector, model, word2idx, idx2word)\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Real: \", reference)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc726132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_src = ['지루하다, 놀러가고 싶어.', '오늘 일찍 일어났더니 피곤하다.',\n",
    "          '간만에 여자친구랑 데이트 하기로 했어.', '집에 있는다는 소리야.']\n",
    "sample_tgt = ['잠깐 쉬 어도 돼요 . <end>', '맛난 거 드세요 . <end>',\n",
    "              '떨리 겠 죠 . <end>', '좋 아 하 면 그럴 수 있 어요 . <end>']\n",
    "test_idx = 0\n",
    "\n",
    "eval_bleu_single(transformer, \n",
    "                 sample_src[test_idx], \n",
    "                 sample_tgt[test_idx], \n",
    "                 tokenizer, \n",
    "                 word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac87e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(model, src_sentences, tgt_sentence, tokenizer, word2idx, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        score = eval_bleu_single(model, src_sentences[idx], tgt_sentence[idx], tokenizer, word2idx, verbose)\n",
    "        if not score: continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_bleu(transformer, sample_src, sample_tgt, tokenizer, word2idx, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
